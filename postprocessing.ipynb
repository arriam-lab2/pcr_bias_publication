{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an OTU table from DADA sequences and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import operator as op\n",
    "from itertools import zip_longest, repeat\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import skbio\n",
    "from biom import Table\n",
    "from biom.util import biom_open\n",
    "from Bio import SeqIO\n",
    "from fn import F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse taxonomy and remove entries lacking a minimum of `MINRANK` classified taxonomic ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'216 entries left out of 282'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MINRANK = 6\n",
    "\n",
    "parse_rank = (\n",
    "    F(re.compile('\\([0-9.]+\\)$').sub, '') >>  # remove confidence scores\n",
    "    (re.compile('isolate').sub, '') >> # remove the 'isolate' postfix\n",
    "    (lambda x: x.replace('_', ' ')) >> \n",
    "    str.strip\n",
    ")\n",
    "\n",
    "def parse_taxa(minrank: int, tax: str):\n",
    "    parsed = [parse_rank(rank) for rank in tax.split(';')][1:7]\n",
    "    return (parsed + ['unknown'] * 6)[:6] if len(parsed) >= minrank else np.nan\n",
    "\n",
    "taxonomy = pd.read_csv(\n",
    "    'dada/taxonomy.tsv', sep='\\t', index_col=0, header=None, names=['seqid', 'tax'],\n",
    "    converters={'tax': F(parse_taxa, MINRANK)}\n",
    ")\n",
    "taxonomy_complete = taxonomy[~taxonomy['tax'].isna()]\n",
    "classified_entries = set(taxonomy_complete.index)\n",
    "\n",
    "f'{len(classified_entries)} entries left out of {len(taxonomy)}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'216 sequences were both classified and inserted into the reference tree'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample metadata\n",
    "metadata = pd.read_csv('metadata.tsv', sep='\\t').set_index('sample', drop=False)\n",
    "\n",
    "# phylogenetic tree\n",
    "with open('tree/tree.nwk') as buffer:\n",
    "    tree = skbio.read(buffer, format=\"newick\", into=skbio.tree.TreeNode)\n",
    "\n",
    "# DADA ASV counts and taxonomy\n",
    "counts = pd.read_csv('dada/counts.tsv', sep='\\t', index_col=0)\n",
    "\n",
    "# remove reference sequences from the tree, subset classified and inserted tips\n",
    "inserted_tips = [tip.name for tip in tree.tips() if tip.name in classified_entries]\n",
    "tree_inserted = tree.shear(inserted_tips)\n",
    "counts_inserted = counts.loc[inserted_tips]\n",
    "\n",
    "f'{len(counts_inserted)} sequences were both classified and inserted into the reference tree'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an OTU table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = counts_inserted.values\n",
    "samples = counts_inserted.keys()\n",
    "observations = counts_inserted.index\n",
    "metadata_keys = ['cycle', 'replicate']\n",
    "\n",
    "sample_metadata = [\n",
    "    row.to_dict() for _, row in metadata.loc[samples, metadata_keys].iterrows()\n",
    "]\n",
    "observation_metadata = [{'taxonomy': tax} for tax in taxonomy_complete.loc[observations, 'tax']]\n",
    "\n",
    "\n",
    "table = Table(data, observations, samples, observation_metadata, sample_metadata, table_id='table')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the OTU table and the sheared tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'stats/tree.nwk'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "! mkdir -p stats\n",
    "\n",
    "with biom_open('stats/table.biom', 'w') as out:  \n",
    "    table.to_hdf5(out, 'table')\n",
    "    \n",
    "skbio.write(tree_inserted, 'newick', 'stats/tree.nwk')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
